{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee94787-26b0-4063-9236-685cee44f84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import gzip\n",
    "import pgeocode\n",
    "#from isdparser import isdparser\n",
    "from meteostat import Point, Hourly\n",
    "#from datetime import datetime\n",
    "import datetime\n",
    "import pathlib\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac3099e-53f6-4065-9c4d-9a3f73dc4790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created or already existed: data/complete_dfs\n",
      "Created or already existed: data/pjm\n",
      "Created or already existed: data/weather\n"
     ]
    }
   ],
   "source": [
    "def getWeatherFilePath(load_area):\n",
    "    filepath = \"data/weather/\" + load_area + \".csv\"\n",
    "    return filepath\n",
    "\n",
    "def getPjmFilePath(year):\n",
    "    filepath = \"data/pjm/\" + \"hrl_load_metered_\" + str(year) + \".csv\"\n",
    "    return filepath\n",
    "\n",
    "def getPjmFreshFilePath():\n",
    "    return \"data/pjm/hrl_load_metered_fresh.csv\"\n",
    "\n",
    "def getCompleteDfFilePath(load_area):\n",
    "    filepath = \"data/complete_dfs/\" + load_area + \".csv\"\n",
    "    return filepath\n",
    "\n",
    "def makeDirectories():\n",
    "    base = pathlib.Path(\"data\")\n",
    "    subdirs = [\"complete_dfs\", \"pjm\", \"weather\"]\n",
    "    for sub in subdirs:\n",
    "        path = base / sub\n",
    "        path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Created or already existed: {path}\")\n",
    "\n",
    "makeDirectories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4b9608-161c-48b4-9c73-d417dab88111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RTO is the *entire PJM footprint*, not a load zone. no meaningful ZIP.\n",
    "zone_to_zips = {\n",
    "    # Atlantic City Electric (Southern New Jersey)\n",
    "    'AECO': ['08401'],   # Atlantic City, NJ\n",
    "    \n",
    "    # American Electric Power - Appalachian Power (central and Southern West Virginia)\n",
    "    'AEPAPT': ['25301'],   # Charleston, WV\n",
    "\n",
    "    # American Electric Power - Indiana Michigan Power (northeast quadrant of indiana and southwest corner of michigan)\n",
    "    'AEPIMP': ['46802'],   # Fort Wayne, IN\n",
    "\n",
    "    # American Electric Power - Kentucky Power (eastern kentucky)\n",
    "    'AEPKPT': ['41101'],   # Ashland, KY (Eastern Kentucky Power region)\n",
    "\n",
    "    # American Electric Power - Ohio (central and southeast ohio)\n",
    "    'AEPOPT': ['43215'],   # Columbus, OH\n",
    "\n",
    "    # Allegheny Power (FirstEnergy West) serving MD/WV/PA panhandle\n",
    "    'AP': ['21502'],     # Cumberland, MD\n",
    "\n",
    "    # Baltimore Gas & Electric\n",
    "    'BC': ['21201'],     # Baltimore, MD (city center)\n",
    "\n",
    "    # Cleveland Electric Illuminating Company (FirstEnergy)\n",
    "    'CE': ['44114'],     # Cleveland, OH (downtown)\n",
    "\n",
    "    # Dayton Power & Light (AES Ohio)\n",
    "    'DAY': ['45402'],    # Dayton, OH\n",
    "\n",
    "    # Duke Energy Ohio/Kentucky load zone\n",
    "    'DEOK': ['45202'],   # Cincinnati, OH\n",
    "\n",
    "    # Dominion Virginia Power\n",
    "    'DOM': ['23219'],    # Richmond, VA\n",
    "\n",
    "    # Delmarva Power (Delaware & Eastern Shore MD)\n",
    "    'DPLCO': ['19901'],  # Dover, DE\n",
    "\n",
    "    # Duquesne Light\n",
    "    'DUQ': ['15222'],    # Pittsburgh, PA\n",
    "\n",
    "    # Easton Utilities (Maryland municipal)\n",
    "    'EASTON': ['21601'], # Easton, MD\n",
    "\n",
    "    # East Kentucky Power Cooperative\n",
    "    'EKPC': ['40391'],   # Winchester, KY\n",
    "\n",
    "    # Jersey Central Power & Light (FirstEnergy NJ)\n",
    "    'JC': ['07728'],     # Freehold, NJ\n",
    "\n",
    "    # Metropolitan Edison (FirstEnergy PA)\n",
    "    'ME': ['19601'],     # Reading, PA\n",
    "\n",
    "    # Ohio Edison (FirstEnergy OH)\n",
    "    'OE': ['44308'],     # Akron, OH\n",
    "\n",
    "    # Ohio Valley Electric Corporation\n",
    "    'OVEC': ['45661'],   # Piketon, OH\n",
    "\n",
    "    # Pennsylvania Power Company (FirstEnergy PA)\n",
    "    'PAPWR': ['16101'],  # New Castle, PA\n",
    "\n",
    "    # PECO (Philadelphia)\n",
    "    'PE': ['19103'],     # Philadelphia, PA (Center City)\n",
    "\n",
    "    # Potomac Electric Power Company (Washington DC + Montgomery Co MD)\n",
    "    'PEPCO': ['20001'],  # Washington, DC\n",
    "\n",
    "    # Potomac Edison (FirstEnergy MD/WV)\n",
    "    'PLCO': ['21740'],   # Hagerstown, MD\n",
    "\n",
    "    # Pennsylvania Electric Company (Penelec - FirstEnergy Northwest/Central PA)\n",
    "    'PN': ['16601'],     # Altoona, PA\n",
    "\n",
    "    # Public Service Electric & Gas (PSE&G NJ)\n",
    "    'PS': ['07102'],     # Newark, NJ\n",
    "\n",
    "    # Rockland Electric (Northern NJ / small NY portion)\n",
    "    'RECO': ['07450'],   # Ridgewood, NJ\n",
    "\n",
    "    # Southern Maryland Electric Cooperative\n",
    "    'SMECO': ['20650'],  # Leonardtown, MD\n",
    "\n",
    "    # UGI Electric (NE Pennsylvania, Luzerne County)\n",
    "    'UGI': ['18702'],    # Wilkes-Barre, PA\n",
    "\n",
    "    # VMEU = Virginia Municipal Electric Utility (multiple small cities)\n",
    "    'VMEU': ['22801']    # Harrisonburg, VA (representative muni)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e712946-e0cc-4f56-88af-d4d864aac759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished checking inconsistencies!\n"
     ]
    }
   ],
   "source": [
    "for year in range(2018,2026):\n",
    "    df = pd.read_csv(getPjmFilePath(year))\n",
    "    #print(df['zone'].unique())\n",
    "    #print(df['load_area'].unique())\n",
    "    #print(len(df['load_area'].unique()))\n",
    "    set1 = set(df['load_area'].unique())\n",
    "    set2 = set(zone_to_zips.keys())\n",
    "    set2.add(\"RTO\")\n",
    "    # Note that years 2016 and 2017 do not match. Thus, we will start with 2018 inclusive\n",
    "    if len(set1.symmetric_difference(set2)) > 0:\n",
    "        print(str(year) + \" did not match! The difference is: \" + str(set1.symmetric_difference(set2)))\n",
    "    \n",
    "print(\"Finished checking inconsistencies!\")\n",
    "years = range(2018,2026)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c64fff20-540f-4fcb-95db-dce506a1c8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached weather file for AECO was found\n",
      "Cached weather file for AEPAPT was found\n",
      "Cached weather file for AEPIMP was found\n",
      "Cached weather file for AEPKPT was found\n",
      "Cached weather file for AEPOPT was found\n",
      "Cached weather file for AP was found\n",
      "Cached weather file for BC was found\n",
      "Cached weather file for CE was found\n",
      "Cached weather file for DAY was found\n",
      "Cached weather file for DEOK was found\n",
      "Cached weather file for DOM was found\n",
      "Cached weather file for DPLCO was found\n",
      "Cached weather file for DUQ was found\n",
      "Cached weather file for EASTON was found\n",
      "Cached weather file for EKPC was found\n",
      "Cached weather file for JC was found\n",
      "Cached weather file for ME was found\n",
      "Cached weather file for OE was found\n",
      "Cached weather file for OVEC was found\n",
      "Cached weather file for PAPWR was found\n",
      "Cached weather file for PE was found\n",
      "Cached weather file for PEPCO was found\n",
      "Cached weather file for PLCO was found\n",
      "Cached weather file for PN was found\n",
      "Cached weather file for PS was found\n",
      "Cached weather file for RECO was found\n",
      "Cached weather file for SMECO was found\n",
      "Cached weather file for UGI was found\n",
      "Cached weather file for VMEU was found\n",
      "Cached weather file for AECO was found\n",
      "                     temp  dwpt  rhum  prcp  snow  wdir  wspd  wpgt  pres  \\\n",
      "time                                                                        \n",
      "2018-01-01 01:00:00 -12.5 -16.2  74.0   NaN   NaN   0.0   0.0   NaN   NaN   \n",
      "2018-01-01 02:00:00 -14.1 -16.9  79.0   NaN   NaN   0.0   0.0   NaN   NaN   \n",
      "2018-01-01 03:00:00 -14.6 -17.4  79.0   NaN   NaN   0.0   0.0   NaN   NaN   \n",
      "2018-01-01 04:00:00 -15.5 -18.2  80.0   NaN   NaN   0.0   0.0   NaN   NaN   \n",
      "2018-01-01 05:00:00 -15.2 -18.0  79.0   NaN   NaN   0.0   0.0   NaN   NaN   \n",
      "\n",
      "                     tsun  coco  \n",
      "time                             \n",
      "2018-01-01 01:00:00   NaN   NaN  \n",
      "2018-01-01 02:00:00   NaN   NaN  \n",
      "2018-01-01 03:00:00   NaN   NaN  \n",
      "2018-01-01 04:00:00   NaN   NaN  \n",
      "2018-01-01 05:00:00   NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "# Create a Nominatim geocoder instance for the desired country (For the USA, use 'us')\n",
    "nomi = pgeocode.Nominatim('us')\n",
    "years = range(2018,2026)\n",
    "\n",
    "def getWeatherDf(load_area, force_refresh=False):\n",
    "    # First check if we have the information cached\n",
    "    file_path = getWeatherFilePath(load_area)\n",
    "    if os.path.exists(file_path) and not force_refresh:\n",
    "        temp = pd.read_csv(file_path)\n",
    "        #print(temp.head())\n",
    "        temp['time'] = pd.to_datetime(temp['time'])\n",
    "        temp = temp.set_index('time')\n",
    "        #print(temp.head())\n",
    "        if temp.index.min().year == years[0] and temp.index.max().year == years[-1]:\n",
    "            print(\"Cached weather file for \" + load_area + \" was found\")\n",
    "            return temp\n",
    "\n",
    "    # Query the postal code\n",
    "    zip_code = value[0]\n",
    "    location_data = nomi.query_postal_code(zip_code)\n",
    "    latitude = float(location_data.latitude)\n",
    "    longitude = float(location_data.longitude)\n",
    "    #print(latitude)\n",
    "    #print(longitude)\n",
    "\n",
    "    location = Point(latitude, longitude)\n",
    "    start = datetime.datetime(years[0], 1, 1)\n",
    "    end   = datetime.datetime(years[-1], 12, 31)\n",
    "\n",
    "    data = Hourly(location, start, end).fetch()\n",
    "    #print(data.head())\n",
    "    data.to_csv(getWeatherFilePath(load_area))\n",
    "    print(\"Added new cached weather file for \" + load_area)\n",
    "    return data\n",
    "\n",
    "for key, value in zone_to_zips.items():\n",
    "    load_area = key\n",
    "    getWeatherDf(load_area)\n",
    "\n",
    "aeco_weather_df = getWeatherDf(\"AECO\")\n",
    "print(aeco_weather_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fbd4772-f843-4f25-8d35-a1eaf69a0aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_holidays = holidays.US(years=years)\n",
    "\n",
    "# Add black friday\n",
    "for year in years:\n",
    "    thanksgiving = [day for day, name in us_holidays.items() if name == \"Thanksgiving Day\" and day.year == year][0]\n",
    "    us_holidays[thanksgiving + datetime.timedelta(days=1)] = \"Black Friday\"\n",
    "    us_holidays[thanksgiving - datetime.timedelta(days=1)] = \"Thanksgiving Eve\"\n",
    "\n",
    "#print(us_holidays)\n",
    "#print(us_holidays.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac9f6cb-8c14-47e7-96ff-6b3bce36c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isHoliday(datetime_obj):\n",
    "     return datetime_obj.date() in us_holidays\n",
    "def isThanksgiving(datetime_obj):\n",
    "    return us_holidays.get(datetime_obj.date()) == \"Thanksgiving Day\"\n",
    "def isThanksgivingEve(datetime_obj):\n",
    "    return us_holidays.get(datetime_obj.date()) == \"Thanksgiving Eve\"\n",
    "def isBlackFriday(datetime_obj):\n",
    "    return us_holidays.get(datetime_obj.date()) == \"Black Friday\"\n",
    "def isWeekend(datetime_obj):\n",
    "    weekno = datetime.datetime.today().weekday()\n",
    "    if weekno < 5:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Thanksgiving 2024 (Nov 28, 2024)\n",
    "#test_dt = datetime.datetime(2024, 11, 29, 15, 0)  # 3pm on Thanksgiving Day\n",
    "#print(isHoliday(test_dt))\n",
    "#print(isBlackFriday(test_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6db3b5f-52b8-48c5-a251-3a6afb8026b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fresh data in addition to historical data\n",
      "                       datetime_beginning_ept nerc_region mkt_region zone  \\\n",
      "datetime_beginning_utc                                                      \n",
      "2025-11-10 00:00:00      11/9/2025 7:00:00 PM         RFC     MIDATL   AE   \n",
      "2025-11-10 01:00:00      11/9/2025 8:00:00 PM         RFC     MIDATL   AE   \n",
      "2025-11-10 02:00:00      11/9/2025 9:00:00 PM         RFC     MIDATL   AE   \n",
      "2025-11-10 03:00:00     11/9/2025 10:00:00 PM         RFC     MIDATL   AE   \n",
      "2025-11-10 04:00:00     11/9/2025 11:00:00 PM         RFC     MIDATL   AE   \n",
      "\n",
      "                       load_area       mw  is_verified  \n",
      "datetime_beginning_utc                                  \n",
      "2025-11-10 00:00:00         AECO  980.590        False  \n",
      "2025-11-10 01:00:00         AECO  952.221        False  \n",
      "2025-11-10 02:00:00         AECO  908.209        False  \n",
      "2025-11-10 03:00:00         AECO  855.014        False  \n",
      "2025-11-10 04:00:00         AECO  799.135        False  \n"
     ]
    }
   ],
   "source": [
    "# Load PJM data\n",
    "\n",
    "def getEnergyDf(load_area):\n",
    "    if load_area not in zone_to_zips.keys():\n",
    "        print(\"Error: load_area(\" + load_area + \") not found!\")\n",
    "        return -1\n",
    "\n",
    "    ret_df = None\n",
    "    for year in years:\n",
    "        pjm_df = pd.read_csv(getPjmFilePath(year))\n",
    "        pjm_df = pjm_df[pjm_df['load_area'] == load_area]\n",
    "        \n",
    "        if ret_df is None:\n",
    "            ret_df = pjm_df\n",
    "        else:\n",
    "            ret_df = pd.concat([ret_df, pjm_df])\n",
    "\n",
    "    # note, this is hardcoded, but whatever\n",
    "    if 2025 in years:\n",
    "        print(\"Loading fresh data in addition to historical data\")\n",
    "        pjm_df = pd.read_csv(getPjmFreshFilePath())\n",
    "        pjm_df = pjm_df[pjm_df['load_area'] == load_area]\n",
    "        if ret_df is None:\n",
    "            ret_df = pjm_df\n",
    "        else:\n",
    "            ret_df = pd.concat([ret_df, pjm_df])\n",
    "\n",
    "    ret_df['datetime_beginning_utc'] = pd.to_datetime(\n",
    "        ret_df['datetime_beginning_utc'], \n",
    "        #utc=True\n",
    "    )\n",
    "    ret_df = ret_df.set_index('datetime_beginning_utc')\n",
    "    ret_df = ret_df.sort_index()   # Always a good idea after setting index\n",
    "\n",
    "    return ret_df\n",
    "\n",
    "aeco_energy_df = getEnergyDf(\"AECO\")\n",
    "print(aeco_energy_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e337a1c9-cf6d-4e5b-9b74-bd1ac360216a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Last step is to augment the pjm data with:\n",
    "# 1) weather at that current time  (we just use the ground truth weather)\n",
    "# 2) previous day's weather\n",
    "# 3) isHoliday, isThanksgiving, isThanksgivingEve, isBlackFriday, isWeekend\n",
    "# 4) lagged loads (24 hrs ago, 168 hrs ago)\n",
    "\n",
    "# The resulting dataframe could be viewed as X,y tuples\n",
    "# in the sense that everything but \n",
    "\n",
    "# weather variables available:\n",
    "# temp\tdwpt\trhum\tprcp\tsnow\twdir\twspd\twpgt\tpres\ttsun\tcoco\n",
    "\n",
    "def add_features(energy_df, weather_df, dropna=True, outer=False):\n",
    "    \"\"\"\n",
    "    df must contain at least:\n",
    "    - load (float)\n",
    "    - temp, dwpt, rhum, wspd, tsun, etc. (weather columns)\n",
    "    - index is hourly timestamps (pd.DatetimeIndex)\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"df = df.merge(\n",
    "    weather_df[['temp']], # Only select 'temp', as the timestamp is the index\n",
    "    left_on='datetime_beginning_utc',\n",
    "    right_index=True,   # Tells pandas to use the index of weather_df (the DatetimeIndex)\n",
    "    how='left'\n",
    "    )\"\"\"\n",
    "    df = energy_df.copy()\n",
    "\n",
    "    if outer:\n",
    "        df = df.join(weather_df[['temp']], how='outer')\n",
    "    else:\n",
    "        df = df.join(weather_df[['temp']], how='left')\n",
    "    \n",
    "    # --- Calendar Features ---\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['month'] = df.index.month\n",
    "    df['is_weekend'] = df['dayofweek'].isin([5,6]).astype(int)\n",
    "\n",
    "    # Holiday features (assuming you already defined isHoliday / isThanksgiving):\n",
    "    df['is_holiday'] = df.index.to_series().apply(isHoliday)\n",
    "    df['is_thanksgiving'] = df.index.to_series().apply(isThanksgiving)\n",
    "    df['is_thanksgiving_eve'] = df.index.to_series().apply(isThanksgivingEve)\n",
    "    df['is_black_friday'] = df.index.to_series().apply(isBlackFriday)\n",
    "\n",
    "    # --- Degree Days ---\n",
    "    df['HDD'] = (18 - df['temp']).clip(lower=0)\n",
    "    df['CDD'] = (df['temp'] - 18).clip(lower=0)\n",
    "\n",
    "    # --- Rolling Weather Averages ---\n",
    "    df['temp_rolling_24'] = df['temp'].rolling('24h', min_periods=1).mean()\n",
    "    # df['dwpt_rolling_24'] = df['dwpt'].rolling(24, min_periods=1).mean()\n",
    "\n",
    "    # --- Lagged Weather Features ---\n",
    "    df['temp_lag_24'] = df['temp'].shift(freq='24h')\n",
    "    df['temp_lag_168'] = df['temp'].shift(freq='168h')\n",
    "\n",
    "    # --- Lagged Load Features (Key Predictors) ---\n",
    "    df['mw_lag_24'] = df['mw'].shift(freq='24h')\n",
    "    df['mw_lag_168'] = df['mw'].shift(freq='168h')\n",
    "\n",
    "    # Drop rows where lag features are missing\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "#df_augmented = add_features(aeco_energy_df, aeco_weather_df, False)\n",
    "#print(df_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d9ebbd7-f548-48a6-b624-c9ed431dd53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached complete file for AECO was found\n",
      "Cached complete file for AEPAPT was found\n",
      "Cached complete file for AEPIMP was found\n",
      "Cached complete file for AEPKPT was found\n",
      "Cached complete file for AEPOPT was found\n",
      "Cached complete file for AP was found\n",
      "Cached complete file for BC was found\n",
      "Cached complete file for CE was found\n",
      "Cached complete file for DAY was found\n",
      "Cached complete file for DEOK was found\n",
      "Cached complete file for DOM was found\n",
      "Cached complete file for DPLCO was found\n",
      "Cached complete file for DUQ was found\n",
      "Cached complete file for EASTON was found\n",
      "Cached complete file for EKPC was found\n",
      "Cached complete file for JC was found\n",
      "Cached complete file for ME was found\n",
      "Cached complete file for OE was found\n",
      "Cached complete file for OVEC was found\n",
      "Cached complete file for PAPWR was found\n",
      "Cached complete file for PE was found\n",
      "Cached complete file for PEPCO was found\n",
      "Cached complete file for PLCO was found\n",
      "Cached complete file for PN was found\n",
      "Cached complete file for PS was found\n",
      "Cached complete file for RECO was found\n",
      "Cached complete file for SMECO was found\n",
      "Cached complete file for UGI was found\n",
      "Cached complete file for VMEU was found\n"
     ]
    }
   ],
   "source": [
    "def getCompleteDf(load_area):\n",
    "    # First check if we have the information cached\n",
    "    file_path = getCompleteDfFilePath(load_area)\n",
    "    if os.path.exists(file_path):\n",
    "        temp = pd.read_csv(file_path)\n",
    "        temp['datetime_beginning_utc'] = pd.to_datetime(temp['datetime_beginning_utc'])\n",
    "        temp = temp.set_index('datetime_beginning_utc')\n",
    "        temp = temp.sort_index()\n",
    "        print(\"Cached complete file for \" + load_area + \" was found\")\n",
    "        return temp\n",
    "\n",
    "    energy_df = getEnergyDf(load_area)\n",
    "    weather_df = getWeatherDf(load_area)\n",
    "    df_augmented = add_features(energy_df, weather_df)\n",
    "    load_area_to_complete_df[load_area] = df_augmented\n",
    "    df_augmented.to_csv(getCompleteDfFilePath(load_area))\n",
    "    print(\"Added new cached complete file for \" + load_area)\n",
    "    return df_augmented\n",
    "\n",
    "def getAllCompleteDfs():\n",
    "    load_area_to_complete_df = {}\n",
    "    for load_area in zone_to_zips.keys():\n",
    "        load_area_to_complete_df[load_area] = getCompleteDf(load_area)\n",
    "\n",
    "# print(getCompleteDf(\"AECO\").head())\n",
    "\n",
    "load_area_to_complete_df = getAllCompleteDfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab5fd67f-92d3-4f13-847f-cdd830738ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fresh data in addition to historical data\n",
      "Added new cached weather file for AECO\n",
      "                    datetime_beginning_ept nerc_region mkt_region zone  \\\n",
      "2025-11-14 00:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 01:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 02:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 03:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 04:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 05:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 06:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 07:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 08:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 09:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 10:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 11:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 12:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 13:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 14:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 15:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 16:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 17:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 18:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 19:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 20:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 21:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 22:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-14 23:00:00                    NaN         NaN        NaN  NaN   \n",
      "2025-11-15 00:00:00                    NaN         NaN        NaN  NaN   \n",
      "\n",
      "                    load_area  mw is_verified  temp  hour  dayofweek  ...  \\\n",
      "2025-11-14 00:00:00      AECO NaN         NaN   4.8     0          4  ...   \n",
      "2025-11-14 01:00:00      AECO NaN         NaN   7.4     1          4  ...   \n",
      "2025-11-14 02:00:00      AECO NaN         NaN   8.8     2          4  ...   \n",
      "2025-11-14 03:00:00      AECO NaN         NaN   8.1     3          4  ...   \n",
      "2025-11-14 04:00:00      AECO NaN         NaN   8.3     4          4  ...   \n",
      "2025-11-14 05:00:00      AECO NaN         NaN   0.5     5          4  ...   \n",
      "2025-11-14 06:00:00      AECO NaN         NaN  -0.1     6          4  ...   \n",
      "2025-11-14 07:00:00      AECO NaN         NaN  -0.7     7          4  ...   \n",
      "2025-11-14 08:00:00      AECO NaN         NaN  -1.1     8          4  ...   \n",
      "2025-11-14 09:00:00      AECO NaN         NaN  -1.4     9          4  ...   \n",
      "2025-11-14 10:00:00      AECO NaN         NaN  -1.5    10          4  ...   \n",
      "2025-11-14 11:00:00      AECO NaN         NaN  -1.5    11          4  ...   \n",
      "2025-11-14 12:00:00      AECO NaN         NaN  -1.5    12          4  ...   \n",
      "2025-11-14 13:00:00      AECO NaN         NaN   1.2    13          4  ...   \n",
      "2025-11-14 14:00:00      AECO NaN         NaN   5.5    14          4  ...   \n",
      "2025-11-14 15:00:00      AECO NaN         NaN   8.5    15          4  ...   \n",
      "2025-11-14 16:00:00      AECO NaN         NaN  11.0    16          4  ...   \n",
      "2025-11-14 17:00:00      AECO NaN         NaN  13.2    17          4  ...   \n",
      "2025-11-14 18:00:00      AECO NaN         NaN  14.8    18          4  ...   \n",
      "2025-11-14 19:00:00      AECO NaN         NaN  15.9    19          4  ...   \n",
      "2025-11-14 20:00:00      AECO NaN         NaN  16.4    20          4  ...   \n",
      "2025-11-14 21:00:00      AECO NaN         NaN  15.9    21          4  ...   \n",
      "2025-11-14 22:00:00      AECO NaN         NaN  12.3    22          4  ...   \n",
      "2025-11-14 23:00:00      AECO NaN         NaN  10.6    23          4  ...   \n",
      "2025-11-15 00:00:00      AECO NaN         NaN   9.4     0          5  ...   \n",
      "\n",
      "                     is_thanksgiving  is_thanksgiving_eve  is_black_friday  \\\n",
      "2025-11-14 00:00:00            False                False            False   \n",
      "2025-11-14 01:00:00            False                False            False   \n",
      "2025-11-14 02:00:00            False                False            False   \n",
      "2025-11-14 03:00:00            False                False            False   \n",
      "2025-11-14 04:00:00            False                False            False   \n",
      "2025-11-14 05:00:00            False                False            False   \n",
      "2025-11-14 06:00:00            False                False            False   \n",
      "2025-11-14 07:00:00            False                False            False   \n",
      "2025-11-14 08:00:00            False                False            False   \n",
      "2025-11-14 09:00:00            False                False            False   \n",
      "2025-11-14 10:00:00            False                False            False   \n",
      "2025-11-14 11:00:00            False                False            False   \n",
      "2025-11-14 12:00:00            False                False            False   \n",
      "2025-11-14 13:00:00            False                False            False   \n",
      "2025-11-14 14:00:00            False                False            False   \n",
      "2025-11-14 15:00:00            False                False            False   \n",
      "2025-11-14 16:00:00            False                False            False   \n",
      "2025-11-14 17:00:00            False                False            False   \n",
      "2025-11-14 18:00:00            False                False            False   \n",
      "2025-11-14 19:00:00            False                False            False   \n",
      "2025-11-14 20:00:00            False                False            False   \n",
      "2025-11-14 21:00:00            False                False            False   \n",
      "2025-11-14 22:00:00            False                False            False   \n",
      "2025-11-14 23:00:00            False                False            False   \n",
      "2025-11-15 00:00:00            False                False            False   \n",
      "\n",
      "                      HDD  CDD  temp_rolling_24  temp_lag_24  temp_lag_168  \\\n",
      "2025-11-14 00:00:00  13.2  0.0         8.937500         11.0           4.0   \n",
      "2025-11-14 01:00:00  10.6  0.0         8.787500         11.0           2.0   \n",
      "2025-11-14 02:00:00   9.2  0.0         8.695833         11.0           1.0   \n",
      "2025-11-14 03:00:00   9.9  0.0         8.575000         11.0          -1.0   \n",
      "2025-11-14 04:00:00   9.7  0.0         8.508333          9.9          -1.0   \n",
      "2025-11-14 05:00:00  17.5  0.0         8.141667          9.3          -1.0   \n",
      "2025-11-14 06:00:00  18.1  0.0         7.795833          8.2          -2.0   \n",
      "2025-11-14 07:00:00  18.7  0.0         7.458333          7.4          -2.0   \n",
      "2025-11-14 08:00:00  19.1  0.0         7.200000          5.1          -3.0   \n",
      "2025-11-14 09:00:00  19.4  0.0         6.991667          3.6          -3.0   \n",
      "2025-11-14 10:00:00  19.5  0.0         6.858333          1.7          -3.0   \n",
      "2025-11-14 11:00:00  19.5  0.0         6.750000          1.1          -3.0   \n",
      "2025-11-14 12:00:00  19.5  0.0         6.604167          2.0          -2.0   \n",
      "2025-11-14 13:00:00  16.8  0.0         6.395833          6.2           2.0   \n",
      "2025-11-14 14:00:00  12.5  0.0         6.200000         10.2           8.0   \n",
      "2025-11-14 15:00:00   9.5  0.0         6.083333         11.3          13.0   \n",
      "2025-11-14 16:00:00   7.0  0.0         6.020833         12.5          14.0   \n",
      "2025-11-14 17:00:00   4.8  0.0         6.004167         13.6          16.0   \n",
      "2025-11-14 18:00:00   3.2  0.0         6.037500         14.0          17.0   \n",
      "2025-11-14 19:00:00   2.1  0.0         6.095833         14.5          18.0   \n",
      "2025-11-14 20:00:00   1.6  0.0         6.195833         14.0          18.0   \n",
      "2025-11-14 21:00:00   2.1  0.0         6.312500         13.1          17.0   \n",
      "2025-11-14 22:00:00   5.7  0.0         6.358333         11.2          17.0   \n",
      "2025-11-14 23:00:00   7.4  0.0         6.475000          7.8          15.0   \n",
      "2025-11-15 00:00:00   8.6  0.0         6.666667          4.8          15.0   \n",
      "\n",
      "                     mw_lag_24  mw_lag_168  \n",
      "2025-11-14 00:00:00        NaN    1030.297  \n",
      "2025-11-14 01:00:00        NaN    1013.396  \n",
      "2025-11-14 02:00:00        NaN     971.824  \n",
      "2025-11-14 03:00:00        NaN     931.829  \n",
      "2025-11-14 04:00:00        NaN     888.421  \n",
      "2025-11-14 05:00:00        NaN     847.042  \n",
      "2025-11-14 06:00:00        NaN     826.556  \n",
      "2025-11-14 07:00:00        NaN     815.267  \n",
      "2025-11-14 08:00:00        NaN     817.725  \n",
      "2025-11-14 09:00:00        NaN     835.460  \n",
      "2025-11-14 10:00:00        NaN     873.884  \n",
      "2025-11-14 11:00:00        NaN     929.639  \n",
      "2025-11-14 12:00:00        NaN     917.034  \n",
      "2025-11-14 13:00:00        NaN     815.222  \n",
      "2025-11-14 14:00:00        NaN     736.582  \n",
      "2025-11-14 15:00:00        NaN     658.874  \n",
      "2025-11-14 16:00:00        NaN     601.289  \n",
      "2025-11-14 17:00:00        NaN     624.328  \n",
      "2025-11-14 18:00:00        NaN     712.425  \n",
      "2025-11-14 19:00:00        NaN     792.055  \n",
      "2025-11-14 20:00:00        NaN     874.783  \n",
      "2025-11-14 21:00:00        NaN     959.621  \n",
      "2025-11-14 22:00:00        NaN    1029.161  \n",
      "2025-11-14 23:00:00        NaN    1020.872  \n",
      "2025-11-15 00:00:00        NaN     998.510  \n",
      "\n",
      "[25 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "def getMidnightToday():\n",
    "    now = datetime.datetime.now()\n",
    "    return now.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def getMidnightTomorrow():\n",
    "    tmrw = datetime.datetime.now() + datetime.timedelta(days=1)\n",
    "    return tmrw.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def getPredictionFeatures(load_area):\n",
    "\n",
    "    energy_df = getEnergyDf(load_area)\n",
    "    weather_df = getWeatherDf(load_area, force_refresh=True)\n",
    "    prediction_df = add_features(energy_df, weather_df, dropna=False, outer=True)\n",
    "\n",
    "    start = getMidnightToday()\n",
    "    end = getMidnightTomorrow()\n",
    "    prediction_df = prediction_df.loc[start:end]\n",
    "    prediction_df[\"load_area\"] = load_area\n",
    "    return prediction_df\n",
    "\n",
    "# Note: The remaining issue is that the energy df that's given in canvas stops october 31. so we lose the mw predictors\n",
    "aeco_prediction_features = getPredictionFeatures(\"AECO\")\n",
    "print(aeco_prediction_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7761281d-f27f-48b6-8a7a-3859cf20f353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-09 00:00:00\n",
      "2025-11-10 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(getMidnightToday())\n",
    "print(getMidnightTomorrow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679550b7-6be7-4ffa-bcac-6763d05ba8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
